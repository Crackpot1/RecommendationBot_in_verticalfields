#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ€§èƒ½åˆ†æè„šæœ¬ - è¯Šæ–­åˆå§‹åŒ–æ…¢çš„åŸå› 
"""

import time
import os
import asyncio
from pathlib import Path
from config import setup_environment, get_pinecone_config, get_model_config
from langchain_community.llms import Ollama
from langchain_community.embeddings import OllamaEmbeddings
from pinecone import Pinecone
import fitz
from pdfminer.high_level import extract_text

def analyze_pdf_files():
    """åˆ†æPDFæ–‡ä»¶å¤§å°å’Œæ•°é‡"""
    print("ğŸ“Š PDFæ–‡ä»¶åˆ†æ")
    print("=" * 50)
    
    pdf_directory = "Recipe material"
    if not os.path.exists(pdf_directory):
        print(f"âŒ ç›®å½• '{pdf_directory}' ä¸å­˜åœ¨")
        return
    
    pdf_files = [f for f in os.listdir(pdf_directory) if f.endswith('.pdf')]
    total_size = 0
    
    print(f"æ‰¾åˆ° {len(pdf_files)} ä¸ªPDFæ–‡ä»¶:")
    for pdf_file in pdf_files:
        file_path = os.path.join(pdf_directory, pdf_file)
        size = os.path.getsize(file_path)
        total_size += size
        print(f"  - {pdf_file}: {size / 1024 / 1024:.2f} MB")
    
    print(f"\næ€»å¤§å°: {total_size / 1024 / 1024:.2f} MB")
    print(f"å¹³å‡å¤§å°: {total_size / len(pdf_files) / 1024 / 1024:.2f} MB")
    
    return pdf_files, total_size

def test_pdf_extraction_speed(pdf_files):
    """æµ‹è¯•PDFæ–‡æœ¬æå–é€Ÿåº¦"""
    print("\nğŸ” PDFæ–‡æœ¬æå–é€Ÿåº¦æµ‹è¯•")
    print("=" * 50)
    
    total_text_length = 0
    total_time = 0
    
    for i, pdf_file in enumerate(pdf_files[:3]):  # åªæµ‹è¯•å‰3ä¸ªæ–‡ä»¶
        file_path = os.path.join("Recipe material", pdf_file)
        print(f"æµ‹è¯•æ–‡ä»¶ {i+1}: {pdf_file}")
        
        start_time = time.time()
        try:
            # ä½¿ç”¨PyMuPDF
            document = fitz.open(file_path)
            text = ""
            for page_num in range(len(document)):
                page = document.load_page(page_num)
                text += page.get_text()
            document.close()
            
            extraction_time = time.time() - start_time
            total_time += extraction_time
            total_text_length += len(text)
            
            print(f"  æå–æ—¶é—´: {extraction_time:.2f}ç§’")
            print(f"  æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")
            print(f"  é€Ÿåº¦: {len(text) / extraction_time / 1000:.2f} Kå­—ç¬¦/ç§’")
            
        except Exception as e:
            print(f"  âŒ æå–å¤±è´¥: {e}")
    
    if total_time > 0:
        print(f"\nå¹³å‡æå–é€Ÿåº¦: {total_text_length / total_time / 1000:.2f} Kå­—ç¬¦/ç§’")

def test_model_initialization():
    """æµ‹è¯•æ¨¡å‹åˆå§‹åŒ–é€Ÿåº¦"""
    print("\nğŸ¤– æ¨¡å‹åˆå§‹åŒ–é€Ÿåº¦æµ‹è¯•")
    print("=" * 50)
    
    setup_environment()
    
    # æµ‹è¯•Pineconeè¿æ¥
    print("æµ‹è¯•Pineconeè¿æ¥...")
    start_time = time.time()
    try:
        pinecone_config = get_pinecone_config()
        pc = Pinecone(api_key=pinecone_config["api_key"])
        index = pc.Index("recipe-index")
        pinecone_time = time.time() - start_time
        print(f"âœ… Pineconeè¿æ¥æˆåŠŸ: {pinecone_time:.2f}ç§’")
    except Exception as e:
        print(f"âŒ Pineconeè¿æ¥å¤±è´¥: {e}")
        return
    
    # æµ‹è¯•Embeddingæ¨¡å‹
    print("æµ‹è¯•Embeddingæ¨¡å‹...")
    start_time = time.time()
    try:
        model_config = get_model_config()
        embeddings = OllamaEmbeddings(model=model_config["embedding_model"])
        embedding_time = time.time() - start_time
        print(f"âœ… Embeddingæ¨¡å‹åˆå§‹åŒ–: {embedding_time:.2f}ç§’")
    except Exception as e:
        print(f"âŒ Embeddingæ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    # æµ‹è¯•LLMæ¨¡å‹
    print("æµ‹è¯•LLMæ¨¡å‹...")
    start_time = time.time()
    try:
        llm = Ollama(
            model=model_config["llm_model"],
            base_url=model_config["ollama_base_url"]
        )
        llm_time = time.time() - start_time
        print(f"âœ… LLMæ¨¡å‹åˆå§‹åŒ–: {llm_time:.2f}ç§’")
    except Exception as e:
        print(f"âŒ LLMæ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    total_model_time = pinecone_time + embedding_time + llm_time
    print(f"\næ¨¡å‹åˆå§‹åŒ–æ€»æ—¶é—´: {total_model_time:.2f}ç§’")

def test_network_speed():
    """æµ‹è¯•ç½‘ç»œè¿æ¥é€Ÿåº¦"""
    print("\nğŸŒ ç½‘ç»œè¿æ¥é€Ÿåº¦æµ‹è¯•")
    print("=" * 50)
    
    import requests
    
    # æµ‹è¯•Pinecone API
    try:
        pinecone_config = get_pinecone_config()
        start_time = time.time()
        response = requests.get(
            "https://api.pinecone.io/",
            headers={"Api-Key": pinecone_config["api_key"]},
            timeout=10
        )
        pinecone_network_time = time.time() - start_time
        print(f"Pinecone APIå“åº”æ—¶é—´: {pinecone_network_time:.2f}ç§’")
    except Exception as e:
        print(f"Pineconeç½‘ç»œæµ‹è¯•å¤±è´¥: {e}")
    
    # æµ‹è¯•Ollama API
    try:
        model_config = get_model_config()
        start_time = time.time()
        response = requests.get(f"{model_config['ollama_base_url']}/api/tags", timeout=10)
        ollama_network_time = time.time() - start_time
        print(f"Ollama APIå“åº”æ—¶é—´: {ollama_network_time:.2f}ç§’")
    except Exception as e:
        print(f"Ollamaç½‘ç»œæµ‹è¯•å¤±è´¥: {e}")

def estimate_initialization_time(pdf_files, total_size):
    """ä¼°ç®—åˆå§‹åŒ–æ—¶é—´"""
    print("\nâ±ï¸ åˆå§‹åŒ–æ—¶é—´ä¼°ç®—")
    print("=" * 50)
    
    # åŸºäºæ–‡ä»¶å¤§å°å’Œæ•°é‡ä¼°ç®—
    estimated_extraction_time = len(pdf_files) * 2  # å‡è®¾æ¯ä¸ªæ–‡ä»¶2ç§’
    estimated_embedding_time = total_size / 1024 / 1024 * 5  # å‡è®¾æ¯MBéœ€è¦5ç§’
    estimated_model_time = 3  # æ¨¡å‹åˆå§‹åŒ–çº¦3ç§’
    
    total_estimated_time = estimated_extraction_time + estimated_embedding_time + estimated_model_time
    
    print(f"PDFæå–ä¼°ç®—æ—¶é—´: {estimated_extraction_time:.1f}ç§’")
    print(f"å‘é‡åŒ–ä¼°ç®—æ—¶é—´: {estimated_embedding_time:.1f}ç§’")
    print(f"æ¨¡å‹åˆå§‹åŒ–ä¼°ç®—æ—¶é—´: {estimated_model_time:.1f}ç§’")
    print(f"æ€»ä¼°ç®—æ—¶é—´: {total_estimated_time:.1f}ç§’")
    
    if total_estimated_time > 60:
        print("âš ï¸ é¢„è®¡åˆå§‹åŒ–æ—¶é—´è¾ƒé•¿ï¼Œå»ºè®®ä½¿ç”¨ç¼“å­˜ä¼˜åŒ–")

def provide_optimization_suggestions(pdf_files, total_size):
    """æä¾›ä¼˜åŒ–å»ºè®®"""
    print("\nğŸ’¡ ä¼˜åŒ–å»ºè®®")
    print("=" * 50)
    
    suggestions = []
    
    if len(pdf_files) > 5:
        suggestions.append("ğŸ“š PDFæ–‡ä»¶è¾ƒå¤šï¼Œå»ºè®®åˆ†æ‰¹å¤„ç†æˆ–ä½¿ç”¨ç¼“å­˜")
    
    if total_size > 50 * 1024 * 1024:  # 50MB
        suggestions.append("ğŸ“ PDFæ–‡ä»¶è¾ƒå¤§ï¼Œå»ºè®®å‹ç¼©æˆ–åˆ†å‰²æ–‡ä»¶")
    
    if len(pdf_files) > 10:
        suggestions.append("âš¡ è€ƒè™‘ä½¿ç”¨å¹¶è¡Œå¤„ç†æé«˜PDFæå–é€Ÿåº¦")
    
    suggestions.append("ğŸ’¾ ä½¿ç”¨å‘é‡åº“ç¼“å­˜é¿å…é‡å¤è®¡ç®—")
    suggestions.append("ğŸ”„ é¢„åŠ è½½æ¨¡å‹å‡å°‘å“åº”æ—¶é—´")
    
    for suggestion in suggestions:
        print(f"  {suggestion}")

def main():
    print("ğŸš€ å¼€å§‹æ€§èƒ½åˆ†æ...")
    print("=" * 60)
    
    # åˆ†æPDFæ–‡ä»¶
    pdf_files, total_size = analyze_pdf_files()
    
    # æµ‹è¯•PDFæå–é€Ÿåº¦
    test_pdf_extraction_speed(pdf_files)
    
    # æµ‹è¯•æ¨¡å‹åˆå§‹åŒ–
    test_model_initialization()
    
    # æµ‹è¯•ç½‘ç»œé€Ÿåº¦
    test_network_speed()
    
    # ä¼°ç®—åˆå§‹åŒ–æ—¶é—´
    estimate_initialization_time(pdf_files, total_size)
    
    # æä¾›ä¼˜åŒ–å»ºè®®
    provide_optimization_suggestions(pdf_files, total_size)
    
    print("\n" + "=" * 60)
    print("âœ… æ€§èƒ½åˆ†æå®Œæˆï¼")
    print("\nğŸ’¡ å»ºè®®ä½¿ç”¨ä¼˜åŒ–ç‰ˆæœ¬: python recipechatbot_optimized.py")

if __name__ == "__main__":
    main() 